wandb_version: 1

activation:
  value: relu
alpha:
  value: 0.0005
batch_size:
  value: 64
epochs:
  value: 5
hidden_layer_size:
  value: 128
learn_rate:
  value: 0.001
n_layers:
  value: 5
optimizer:
  value: momentum_gradient_descent
weight_init:
  value: random
